---
layout: post
title:  "朴素贝叶斯"
date:   2020-03-17 21:08:06 +0800--
categories: [机器学习,]
tags: [贝叶斯, 机器学习, 概率, ]  
---



# 朴素贝叶斯

> 在夏季，某公园男性穿凉鞋的概率为 1/2 ，女性穿凉鞋的概率为 2/3 ，并且该公园中男女比例通常为 2:1 ，问题：若你在公园中随机遇到一个穿凉鞋的人，请问他的性别为男性或女性的概率分别为多少？

### 先验概率

**先验概率（prior probability）**是指根据以往经验和分析得到的概率，如全概率公式（后面会讲）。
  我们使用以上例子来解释一下什么是先验概率。根据以上例子我们设定：假设某公园中一个人是男性为事件 $𝑌=𝑦𝑚𝑒𝑛$ ,是女性则是 $𝑌=𝑦𝑤𝑜𝑚𝑒𝑛$ ；一个人穿凉鞋为事件 $𝑋=𝑥1$ ，未穿凉鞋为事件$ 𝑋=𝑥0$。而一个人的性别与是否穿凉鞋这两个事件之间是**相互独立**的。

于是我们可以看到该例子中存在四个先验概率：


$$
𝑃(𝑋=𝑥1)与𝑃(𝑋=𝑥0)
$$

$$
𝑃(𝑌=𝑦𝑚𝑒𝑛)与𝑃(𝑌=𝑦𝑤𝑜𝑚𝑒𝑛)
$$

其中 $𝑃(𝑌=𝑦𝑚𝑒𝑛)$与$𝑃(𝑌=𝑦𝑤𝑜𝑚𝑒𝑛)$可以根据例子中“该公园中男女比例通常为 2:1 ” 这一以往经验求得：$𝑃(𝑌=𝑦𝑚𝑒𝑛)=23$以及 $𝑃(𝑌=𝑦𝑤𝑜𝑚𝑒𝑛)=13$。而先验概率 $𝑃(𝑌=𝑦𝑚𝑒𝑛)与𝑃(𝑌=𝑦𝑤𝑜𝑚𝑒𝑛)$ 并不能直接得出，需要根据**全概率公式**来求解。在学习全概率公式之前，我们先了解一下**条件概率**。



### 条件概率

设A、B是两个事件，在A事件发生的条件下，B事件发生的概率，其中P（A）>0。说明A事件发生的概率大于0,表示A事件是必然发生的，记为


$$
P(B|A)=\frac{P(AB)}{P(A)}\qquad=\frac{P(A|B)P(B)}{P(A)}\qquad
$$


⭐️ 转换为分类任务的表达式：


$$
P(类别|特征)=\frac{P(特征|类别)P(类别)}{P(特征)}\qquad
$$


![image-20200316173441688](/assets/imgs/image-20200316173441688.png)



### 全概率公式

全概率公式，（有原因到结果）即观察样本空间每一个划分与A事件相交发生的概率，并把各划分与A事件相交概率进行累加，并最终计算A的总概率。

简单说即观察每一种事件A发生的概率，计算A的概率P（A）。


$$
P(A)=P(AB1)P(AB2)P(AB3)P(AB4)P(AB5)P(AB6)
=P(A|B1)P(B1)+P(A|B2)P(B2)+P(A|B3)P(B3)+P(A|B4)P(B4)+P(A|B5)P(B5)+P(A|B6)P(B6)
$$

$$
𝑃(𝑋=𝑥)=\sum_{𝑖=1}^{𝑛}𝑃(𝑌=𝑦𝑖)𝑃(𝑋=𝑥|𝑌=𝑦𝑖)
$$



### 贝叶斯公式

与全概率公式正好相反（有结果求原因）在事件A发生的条件下，观察每一种情况出现的条件概率。即已知P(A)的概率，求分割事件Bi条件的概率。

定义：设随机试验E的样本空间为S，A为随机试验的事件，B1~Bn为S的一个划分，且P(A)>0,P(Bi)>0,(i=1,2,…n),则


$$
P(Bi|A)=\frac{P(A|Bi)P(Bi)}{\sum_{j=1}^{n}P(A|Bj)P(Bj)}\qquad=\frac{P(BiA)}{P(A)}\qquad
$$

解释：分子就是你所求的划分事件Bi和A事件的相交的概率，而分母其实就是个全概率公式，即也是A的概率，在这里一般往往是已知的,或者是相对比较容易求得的。				
					

### 后验概率

**后验概率**是指，某事件 $𝑋=𝑥$ 已经发生，那么该事件是因为事件 $𝑌=𝑦$ 的而发生的概率。也就是上例中所需要求解的“在知道一个人穿拖鞋的前提下，这个人是男性的概率或者是女性的概率是多少”。后验概率形式化便是：


$$
𝑃(𝑌=𝑦𝑚𝑒𝑛|𝑋=𝑥1)
$$

**后验概率**的计算要以先验概率为基础。后验概率可以根据通过**贝叶斯公式**，用**先验概率**和**似然函数**计算出来。
**贝叶斯公式**如下：


$$
𝑃(𝑌=𝑦𝑚𝑒𝑛|𝑋=𝑥1)=\frac{𝑃(𝑋=𝑥1|𝑌=𝑦𝑚𝑒𝑛)𝑃(𝑌=𝑦𝑚𝑒𝑛)}{𝑃(𝑋=𝑥1)}=\frac{𝑃(𝑋=𝑥1|𝑌=𝑦𝑚𝑒𝑛)𝑃(𝑌=𝑦𝑚𝑒𝑛)}{∑_{𝑖={𝑚𝑒𝑛,𝑤𝑜𝑚𝑒𝑛}}𝑃(𝑌=𝑦𝑖)𝑃(𝑋=𝑥1|𝑌=𝑦𝑖)}
$$
  其中 $𝑃(𝑌=𝑦𝑚𝑒𝑛|𝑋=𝑥1)$ 为所求**后验概率**，$𝑃(𝑋=𝑥1|𝑌=𝑦𝑚𝑒𝑛)$ 为**条件概率**，$𝑃(𝑌=𝑦𝑚𝑒𝑛)$ 为**先验概率**， $𝑃(𝑋=𝑥1)=∑𝑖={𝑚𝑒𝑛,𝑤𝑜𝑚𝑒𝑛}𝑃(𝑌=𝑦𝑖)$为**全概率公式**。



**而朴素贝叶斯算法正是利用以上信息求解后验概率，并依据后验概率的值来进行分类。**

  使用上面的例子来进行理解，后验概率为：



$$
𝑃(𝑌=𝑦𝑚𝑒𝑛|𝑋=𝑥1)=𝑃(𝑋=𝑥1|𝑌=𝑦𝑚𝑒𝑛)𝑃(𝑌=𝑦𝑚𝑒𝑛)𝑃(𝑋=𝑥1)=\frac{1/2×2/3}{5/9}=3/5
$$

$$
𝑃(𝑌=𝑦𝑤𝑜𝑚𝑒𝑛|𝑋=𝑥1)=𝑃(𝑋=𝑥1|𝑌=𝑦𝑤𝑜𝑚𝑒𝑛)𝑃(𝑌=𝑦𝑤𝑜𝑚𝑒𝑛)𝑃(𝑋=𝑥1)=\frac{2/3×1/3}{5/9}=2/5
$$



  也就是说，在知道一个人穿拖鞋的前提下，这个人是男性的概率是 3535 ,是女性的概率是 2525 。如果问题是“判断该人是男性还是女性”，此问题就是一个分类问题。由于依据贝叶斯公式计算的后验概率是男性的概率大于是女性的概率，即由于 $𝑃(𝑌=𝑦𝑚𝑒𝑛|𝑋=𝑥1)>𝑃(𝑌=𝑦𝑤𝑜𝑚𝑒𝑛|𝑋=𝑥1)$ ，那么我们就可以将其**分类为男性**（实际在使用朴素贝叶斯进行分类时，不需要求解分母 $𝑃(𝑋=𝑥1)$。
  到此，我们已经使用例子来讲解了使用**朴素贝叶斯**进行分类的基本步骤以及简单的原理了。接下来我们将对**朴素贝叶斯**的原理进行详细地探讨。



### 朴素贝叶斯的推导

对于样本集:


$$
𝐷=\{(𝑥^{(1)}_{1},𝑥^{(1)}_{2},...,𝑥^{(1)}_{n},y_1),(𝑥^{(2)}_{1},𝑥^{(2)}_{2},...,𝑥^{(2)}_{n},y_2),...,(𝑥^{(m)}_{1},𝑥^{(m)}_{2},...,𝑥^{(m)}_{n},y_m)\}
$$


 其中 $𝑚$表示有 $𝑚$ 个样本， $𝑛$ 表示有 𝑛n 个特征。 $𝑦𝑖,𝑖=1,2,..,𝑚$ 表示样本类别，取值为 ${𝐶1,𝐶2,...,𝐶𝐾}$ 。

**先验概率**为：


$$
𝑃(𝑌=𝐶_𝑘),𝑘=1,2,...,𝐾
$$

条件概率为（依据条件独立假设）：


$$
𝑃(𝑋=𝑥|𝑌=𝐶_𝑘)=𝑃(𝑋_1=𝑥_1,𝑋_2=𝑥_2,...,𝑋_𝑛=𝑥_𝑛|𝑌=𝐶_𝑘)=∏_{𝑗=1}^𝑛𝑃(𝑋_𝑗=𝑥_𝑗|𝑌=𝐶_𝑘)
$$
则**后验概率**为：


$$
𝑃(𝑌=𝐶_𝑘|𝑋=𝑥)=\frac{𝑃(𝑋=𝑥|𝑌=𝐶_𝑘)𝑃(𝑌=𝐶_𝑘)}{∑_𝑘𝑃(𝑋=𝑥|𝑌=𝐶_𝑘)𝑃(𝑌=𝐶_𝑘)}
$$
将**条件概率**公式带入得：


$$
𝑃(𝑌=𝐶𝑘|𝑋=𝑥)=\frac{𝑃(𝑌=𝐶_𝑘)∏^𝑛_{𝑗=1}𝑃(𝑋_𝑗=𝑥_𝑗|𝑌=𝐶_𝑘)}{∑_𝑘𝑃(𝑌=𝐶_𝑘)∏^𝑛_{𝑗=1}𝑃(𝑋_𝑗=𝑥_𝑗|𝑌=𝐶_𝑘)}
$$
上式为朴素贝叶斯分类的基本公式。于是，朴素贝叶斯分类器可表示为：

![image-20200317203808109](/assets/imgs/image-20200317203808109.png)

由于分母对所有的 $𝐶_𝑘$ 都是相同的，所以：

![image-20200317203836913](/assets/imgs/image-20200317203836913.png)



# 参数估计

### 极大似然估计

极大似然估计的原理，用一张图片来说明，如下图所示：

![image-20200317204218547](/assets/imgs/image-20200317204218547.png)

总结起来，最大似然估计的目的就是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。

​    原理：极大似然估计是建立在极大似然原理的基础上的一个统计方法，是概率论在统计学中的应用。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。



针对样本集我们可以利用**极大似然估计**计算出以下一些信息：


$$
先验概率：𝑃(𝑌=𝐶_𝑘)=\frac{∑^𝑚_{𝑖=1}𝐼(𝑦_𝑖=𝐶_𝑘)}{𝑚}，𝑘=1,2,...,𝐾
$$


其中 $∑^𝑚_{𝑖=1}𝐼(𝑦_𝑖=𝐶_𝑘)$计算的是样本类别为 $𝐶𝑘$ 的总数。先验概率计算的是类别 $𝐶𝑘$ 在样本集中的频率。


$$
条件概率：𝑃(𝑋_𝑗=𝑎_{𝑗𝑙}|𝑌=𝐶_𝑘)=\frac{∑^𝑚_{𝑖=1}𝐼(𝑥_𝑗^{(i)}=𝑎_{𝑗𝑙},𝑦_𝑖=𝐶_𝑘)}{∑^𝑚_{𝑖=1}𝐼(𝑦_𝑖=𝐶_𝑘)}
$$


其中第 𝑗 个特征的取值可能是 ${𝑎𝑗1,𝑎𝑗2,...,𝑎𝑗ℎ}$，共 ℎ 个。该条件概率指的是，在样本类别为 $𝐶_𝑘$ 的子样本集中，第 𝑗 个特征取值为 $𝑎_{𝑗𝑙}$ 的样本的频率。



### 贝叶斯估计

为了弥补极大似然估计中可能出现概率值为0的情况（也就是某个事件出现的次数为0）。于是使用**贝叶斯估计**，如下：


$$
先验概率：𝑃(𝑌=𝐶_𝑘)=\frac{∑^𝑚_{𝑖=1}𝐼(𝑦_𝑖=𝐶_𝑘)}{𝑚+K\lambda}，𝑘=1,2,...,𝐾
$$


其中 𝐾 为类别的个数。


$$
条件概率：𝑃(𝑋_𝑗=𝑎_{𝑗𝑙}|𝑌=𝐶_𝑘)=\frac{∑^𝑚_{𝑖=1}𝐼(𝑥_𝑗^{(i)}=𝑎_{𝑗𝑙},𝑦_𝑖=𝐶_𝑘)+\lambda}{∑^𝑚_{𝑖=1}𝐼(𝑦_𝑖=𝐶_𝑘)+S_j\lambda}
$$


其中 $𝑆_𝑗$ 为特征 $𝑋_𝑗$ 取值的个数 ℎ 。



# 朴素贝叶斯算法过程

以**参数估计为极大似然估计**为例：
样本集为：


$$
𝐷=\{(𝑥^{(1)}_{1},𝑥^{(1)}_{2},...,𝑥^{(1)}_{n},y_1),(𝑥^{(2)}_{1},𝑥^{(2)}_{2},...,𝑥^{(2)}_{n},y_2),...,(𝑥^{(m)}_{1},𝑥^{(m)}_{2},...,𝑥^{(m)}_{n},y_m)\}
$$


其中 $𝑦𝑖,𝑖=1,2,..,𝑚$表示样本类别，取值为 ${𝐶1,𝐶2,...,𝐶_𝐾}$。
1）计算**先验概率**：求出样本类别的个数 𝐾 。对于每一个样本 $𝑌=𝐶_𝑘$ ，计算出 $𝑃(𝑌=𝐶_𝑘)$ 。其为类别 𝐶𝑘在总样本集中的频率。
2）计算**条件概率**：将样本集划分成 𝐾 个子样本集，分别对属于 $𝐶_𝑘$ 的子样本集进行计算，计算出其中特征 $𝑋𝑗=𝑎_{𝑗𝑙}$的概率： $𝑃(𝑋_𝑗=𝑎_{𝑗𝑙}|𝑌=𝐶_𝑘)$。其为该子集中特征取值为 $𝑎_{𝑗𝑙}$ 的样本数与该子集样本数的比值。
3）针对待预测样本 $𝑥𝑡𝑒𝑠𝑡$ ，计算其对于每个类别 𝐶𝑘 的**后验概率**：

$𝑃(𝑌=𝐶_𝑘|𝑋=𝑥^𝑡𝑒𝑠𝑡)=𝑃(𝑌=𝐶_𝑘)∏^𝑛_{𝑗=1}𝑃(𝑋_𝑗=𝑥^𝑡𝑒𝑠𝑡_𝑗|𝑌=𝐶_𝑘)$ 。概率值最大的类别即为待预测样本的预测**类别**。



# 朴素贝叶斯算法分析

**优点**：

1）朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。
2）对小规模的数据表现很好，能个处理多分类任务，适合增量式训练，尤其是数据量超出内存时，我们可以一批批的去增量训练。
3）对缺失数据不太敏感，算法也比较简单，常用于文本分类。
**缺点**：
1）理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型给定输出类别的情况下,假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。
2）需要知道先验概率，且先验概率很多时候取决于假设，假设的模型可以有很多种，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳。
3）由于我们是通过先验和数据来决定后验的概率从而决定分类，所以分类决策存在一定的错误率。
4）对输入数据的表达形式很敏感。