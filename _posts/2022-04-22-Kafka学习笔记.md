---
layout: post
title:  "Kafka学习笔记"
date:   2022-04-22 12:19:06 +0800--
categories: [Kafka]
tags: [Kafka, ]  
---

# Kafka概述

Kafka是一个分布式的基于发布/订阅模式的消息队列(Message Queue)，主要应用于大数据实时处理领域。



## 消息队列的两种模式

### 点对点模式

**一对一，消费者主动拉取数据，消息收到后消息清除。**消息生产者生产消息发送到 Queue 中，然后消息消费者从 Queue 中取出并且消费消息。消息被消费以后，Queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。 Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。

![image-20220425222529896](/assets/imgs/image-20220425222529896.png)

### 发布/订阅模式

**一对多，消费者消费数据之后不会清除消息。**消息生产者(发布)将消息发布到 topic 中，同时有多个消息消费者(订阅)消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。该模式具体可分为拉和推两种方式：

- 队列主动推送：各个消费者处理的速率不同，可能会导致消费者资源浪费或不足。
- 消费者主动拉取：长轮询

![image-20220425222547643](/assets/imgs/image-20220425222547643.png)

## Kafka 基础架构

![image-20220426141607627](/assets/imgs/image-20220426141607627.png)

- **Producer**:消息生产者，就是向 Kafka broker 发消息的客户端
- **Consumer**:消息消费者，向 Kafka broker 取消息的客户端
- **Consumer Group**(**CG**):消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费;消费者组之间互不 影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。
- **Broker**:一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。
- **Topic**:可以理解为一个队列，生产者和消费者面向的都是一个 **topic**。
- **Partition**:为了实现扩展性，一个非常大的 topic 可以分布到多个 broker(即服 务器)上，一个 **topic** 可以分为多个 **partition**，每个 partition 是一个有序的队列。
- **Replica**:副本。一个 topic 的每个分区都有若干个副本，一个 **Leader** 和若干个 **Follower**。
- **Leader**:每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数 据的对象都是 Leader。
- **Follower**:每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。

# Kafka快速入门

## 单机部署

1）解压安装包

```shell
tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/
```

2）创建logs日志文件夹

```shell
mkdir ~/Application/kafka_2.12-3.0.0/logs
```

3）修改配置文件

```shell
vim kafka_2.12-3.0.0/config/server.properties
```

```shell
#broker 的全局唯一编号，不能重复 broker.id=0
#删除 topic 功能使能
delete.topic.enable=true
#处理网络请求的线程数量 
num.network.threads=3
#用来处理磁盘 IO 的现成数量 
num.io.threads=8 
#发送套接字的缓冲区大小 
socket.send.buffer.bytes=102400 
#接收套接字的缓冲区大小 
socket.receive.buffer.bytes=102400 
#请求套接字的缓冲区大小 
socket.request.max.bytes=104857600 
#kafka 运行数据和日志存放的路径 
log.dirs=~/Application/kafka_2.12-3.0.0/logs
#topic 在当前 broker 上的分区个数 
num.partitions=1
#用来恢复和清理 data 下数据的线程数量 
num.recovery.threads.per.data.dir=1 
#segment 文件保留的最长时间，超时将被删除 
log.retention.hours=168
#配置连接 Zookeeper 集群地址 
zookeeper.connect=localhost:2181/kafka
```

4）依次启动zookeeper和kafka(Kafka会按照默认，在**9092**端口上运行，并连接zookeeper的默认端口：2182)

```shell
cd ~/Applications/ZooKeeper
bin/zkServer.sh start
~/Application/kafka_2.12-3.0.0
sh bin/kafka-server-start.sh  -daemon  config/server.properties # -daemon 后台启动kafka
```

如kafka启动报错：在 server.properties 找到  log.dirs 配置的路径。将该路径下的所有文件删除，或者编辑meta.properties文件修改里面的cluster.id即可。

```java
ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.InconsistentClusterIdException: The Cluster ID kVSgfurUQFGGpHMTBqBPiw doesn't match stored clusterId Some(0Qftv9yBTAmf2iDPSlIk7g) in meta.properties. The broker is trying to join the wrong cluster. Configured zookeeper.connect may be wrong.
    at kafka.server.KafkaServer.startup(KafkaServer.scala:220)
    at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
    at kafka.Kafka$.main(Kafka.scala:84)
    at kafka.Kafka.main(Kafka.scala)
```





## 主题命令行操作

1）查看操作主题命令参数

```shell
bin/kafka-topics.sh
```

![image-20220426130141201](/assets/imgs/image-20220426130141201.png)

2）查看当前服务器中的所有 topic

```shell
bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
```

3）创建 first topic

```shell
# --topic 定义topic名 --replication-factor 定义副本数 --partitions 定义分区数
bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --partitions 1 --replication-factor 3 --topic first
```

4）查看 first 主题的详情

```shell
bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic first
```

5）修改分区数(注意:分区数只能增加，不能减少)

```shell
bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic first --partitions 3
```

6）删除 topic

```shell
bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic first
```

  

## 生产者命令行操作

1）查看操作生产者命令参数

```shell
bin/kafka-console-producer.sh
```

![image-20220426140913384](/assets/imgs/image-20220426140913384.png)

2）发送消息

```shell
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first
>hello world
```



## 消费者命令行操作

1）查看操作消费者命令参数

| 参数                                             | 描述                                 |
| ------------------------------------------------ | ------------------------------------ |
| --bootstrap-server <String: server toconnect to> | 连接的 Kafka Broker 主机名称和端口号 |
| --topic <String: topic>                          | 操作的 topic 名称                    |
| --from-beginning                                 | 从头开始消费                         |
| --group <String: consumer group id>              | 指定消费者组名称                     |

2）消费消息

```shell
# 消费 first 主题中的数据
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first
# 把主题中所有的数据都读取出来(包括历史数据)
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic first
```





# Kafka 生产者

## 生产者消息发送流程

### 发送原理

在消息发送的过程中，涉及到了两个线程：**main** 线程和 **Sender** 线程。在 main 线程 中创建了一个双端队列 **RecordAccumulator**。main 线程通过分区器将消息发送给 RecordAccumulator， Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka Broker。

![image-20220426144944892](/assets/imgs/image-20220426144944892.png)

- **batch.size**：只有数据积累到batch.size之后，sender才会发送数据，默认16k 
- **linger.ms**：如果数据迟迟未达到batch.size,sender等待linger.ms设置的时间。到了之后就会发送数据，单位ms，默认值是0ms，表示没有延迟。

应答acks：

- 0：生产者发送过来的数据，不需要等数据落盘应答。
- 1：生产者发送过来的数据，Leader 收到数据后应答。
- -1(all)：生产者发送过来的数据，Leader 和 ISR 队列 里面的所有节点收齐数据后应答。-1和 all 等价。



### 生产者重要参数列表

| 参数名称                              | 描述                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| bootstrap.servers                     | 生产者连接集群所需的 broker 地址清单。例如 hadoop102:9092,hadoop103:9092,hadoop104:9092，可以设置 1 个或者多个，中间用逗号隔开。注意这里并非需要所有的 broker 地址，因为生产者从给定的 broker 里查找到其他 broker 信息。 |
| key.serializer 和 value.serializer    | 指定发送消息的 key 和 value 的序列化类型。一定要写 全类名。  |
| buffer.memory                         | RecordAccumulator 缓冲区总大小，默认 32m。                   |
| batch.size                            | 缓冲区一批数据最大值，默认 16k。适当增加该值，可 以提高吞吐量，但是如果该值设置太大，会导致数据 传输延迟增加。 |
| linger.ms                             | 如果数据迟迟未达到 batch.size，sender 等待 linger.time 之后就会发送数据。单位 ms，默认值是 0ms，表示没 有延迟。生产环境建议该值大小为 5-100ms 之间。 |
| acks                                  | 0：生产者发送过来的数据，不需要等数据落盘应答。 1：生产者发送过来的数据，Leader 收到数据后应答。 -1(all)：生产者发送过来的数据，Leader 和 ISR 队列 里面的所有节点收齐数据后应答。-1和 all 等价。 |
| max.in.flight.requests.per.connection | 允许最多没有返回 ack 的次数，默认为 5，开启幂等性 要保证该值是 1-5 的数字。 |
| retries                               | 当消息发送出现错误的时候，系统会重发消息。retries 表示重试次数。默认是 int 最大值，2147483647。 如果设置了重试，还想保证消息的有序性，需要设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1 否则在重试此失败消息的时候，其他的消息可能发送成功了。 |
| retry.backoff.ms                      | 两次重试之间的时间间隔，默认是 100ms。                       |
| enable.idempotence                    | 是否开启幂等性，默认 true，开启幂等性。                      |
| compression.type                      | 生产者发送的所有数据的压缩方式。默认是 none，也 就是不压缩。 支持压缩类型:none、gzip、snappy、lz4 和 zstd。 |



## 异步发送 **API**

### 普通异步发送

> 需求:创建 Kafka 生产者，采用**异步**的方式(外部数据无须等到当前batch被RecordAccumulator处理完后再载入)发送到 Kafka Broker

1）创建工程，导入依赖

```html
<dependency>
  <groupId>org.springframework.kafka</groupId>
  <artifactId>spring-kafka-test</artifactId>
  <scope>test</scope>
</dependency>
```



2）编写不带回调函数的 API 代码

```java
/**
 * kafka 生产者
 *
 * @author zhongye
 * @since 2022.04.26
 */
public class CustomProducer {
  public static void main(String[] args) {
    // 0 配置
    Properties properties = new Properties();
    // 连接集群 bootstrap.servers
    properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092");
    // 指定对应的key和value的序列化类型 key.serializer
    properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    // 1 创建kafka生产者对象
    KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

    // 2 发送数据
    for (int i = 0; i < 5; i++) {
      kafkaProducer.send(new ProducerRecord<>("first","silince"+i));
    }

    // 3 关闭资源
    kafkaProducer.close();
  }
}
```

### 带回调函数的异步发送

回调函数会在 producer 收到 ack 时调用，为异步调用，该方法有两个参数，分别是元数据信息(RecordMetadata)和异常信息(Exception)，如果 Exception 为 null，说明消息发送成功，如果 Exception 不为 null，说明消息发送失败。

⚠️：消息发送失败会自动重试，不需要我们在回调函数中手动重试。

```java
kafkaProducer.send(new ProducerRecord<>("first", "silince" + i), new Callback() {
  @Override
  public void onCompletion(RecordMetadata recordMetadata, Exception e) {
    if (e==null){
      System.out.println("主题: "+recordMetadata.topic()+" 分区: "+recordMetadata.partition());
    }
  }
```



## 同步发送 **API**

同步发送(当前batch全部正常ack之后再载入下一批外部数据)只需在异步发送的基础上，再调用一下 get()方法即可。

```java
/**
 * kafka 生产者
 *
 * @author zhongye
 * @since 2022.04.26
 */
public class CustomProducer {
  public static void main(String[] args) throws Exception {
    // 0 配置
    Properties properties = new Properties();
    // 连接集群 bootstrap.servers
    properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092");
    // 指定对应的key和value的序列化类型 key.serializer
    properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    // 1 创建kafka生产者对象
    KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

    // 2 发送数据
    for (int i = 0; i < 5; i++) {
      kafkaProducer.send(new ProducerRecord<>("first", "silince" + i)).get();
    }

    // 3 关闭资源
    kafkaProducer.close();
  }
}
```



## 分区策略

> [Kafka 分区](http://www.silince.cn/2021/08/26/Kafka-%E5%88%86%E5%8C%BA/)



## 生产经验

### 如何提高吞吐量

- batch.size：批次大小, 默认16k 
- linger.ms：等待时间,修改为5-100ms(太大的话会导致下一批数据的延迟过高)
- compression.type：压缩snappy
- RecordAccumulator：缓冲区大小,修改为64m

```java
// 1. 创建 kafka 生产者的配置对象
Properties properties = new Properties();
// 2. 给 kafka 配置对象添加配置信息:bootstrap.servers
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
// key,value 序列化(必须):key.serializer，value.serializer
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
// batch.size:批次大小，默认16K 
properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
// linger.ms:等待时间，默认 0 
properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);
// RecordAccumulator:缓冲区大小，默认 32M:buffer.memory 
properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,33554432);
// compression.type:压缩，默认 none，可配置值 gzip、snappy、 lz4 和 zstd
properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG,"snappy");
```



### 数据可靠性

1）ACKS应答级别

- 0:生产者发送过来的数据，不需要等数据落盘应答(可靠性差，效率高)

  ![image-20220428143600531](/assets/imgs/image-20220428143600531.png)

- 1:生产者发送过来的数据，**Leader**收到数据后应答(可靠性中等，效率中等)

  ![image-20220428143612384](/assets/imgs/image-20220428143612384.png)

- -1(all):生产者发送过来的数据，**Leader**和**ISR**队列里面 的所有节点收齐数据后应答(**可靠性高，效率低;在生产环境中，acks=0很少使用;acks=1，一般用于传输普通日志，允许丢个别数据;acks=-1，一般用于传输和钱相关的数据， 对可靠性要求比较高的场景**)

  ![image-20220428143629255](/assets/imgs/image-20220428143629255.png)

> 🤔 当acks=-1时，Leader收到数据，所有Follower都开始同步数据， 但有一个Follower，因为某种故障，迟迟不能与Leader进行 同步，那这个问题怎么解决呢?

**Leader维护了一个动态的in-sync replica set(ISR)，意为和 Leader保持同步的Follower+Leader集合(leader:0，isr:0,1,2)。**

**如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由replica.lag.time.max.ms参数设定，默认30s。例如2超时，这ISR变为(leader:0, isr:0,1)。这样就不用等长期联系不上或者已经故障的节点。**

**数据可靠性分析:**如果分区副本设置为1个，或者ISR里应答的最小副本数量 ( min.insync.replicas 默认为1)设置为1，和ack=1的效果是一 样的，仍然有丢数的风险(leader:0，isr:0)。

因此==**数据完全可靠条件 = ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于**2==



2）代码配置

```java
// 0 配置
Properties properties = new Properties();
// 连接集群 bootstrap.servers
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092");
// 指定对应的key和value的序列化类型 key.serializer
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

// acks + 重试次数
properties.put(ProducerConfig.ACKS_CONFIG,"1");
properties.put(ProducerConfig.RETRIES_CONFIG,3);
```





### 数据重复

acks: **-1**(**all**):生产者发送过来的数据，**Leader**和**ISR**队列里面的所有节点收齐数据后应答。如果Leader同步数据之后，没来得及确认ack就挂掉了，则新选举的Leader则会又收到一份重复数据。

![image-20220428153413825](/assets/imgs/image-20220428153413825.png)

1）数据传递语义

- 至少一次(**At Least Once**)=ACK级别设置为-1**+**分区副本大于等于2**+**ISR里应答的最小副本数量大于等于2 。可以保证数据不丢失，但是不能保证数据不重复; 
- 最多一次(**At Most Once**)**=**ACK级别设置为0。可以保证数据不重复，但是不能保证数据不丢失。

- 精确一次(**Exactly Once**):对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失。 

Kafka 0.11版本以后，引入了一项重大特性:幂等性和事务。



2）幂等性

幂等性就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。 

精确一次(**Exactly Once**) **=** 幂等性 **+** 至少一次( **ack=-1 +** 分区副本数**>=2 + ISR**最小副本数量**>=2**) 。

**重复数据的判断标准**：具有`<PID, Partition, SeqNumber>`相同主键的消息提交时，Broker只会持久化一条。

- PID：Kafka每次重启都会分配一个新的pid
- Partition：分区号
- Sequence Number：序列号，单调自增

==所以幂等性只能保证的是在单分区单会话内不重复。==

![image-20220428164642695](/assets/imgs/image-20220428164642695.png)

使用方式：开启参数 **enable.idempotence** 默认为 true，false 关闭。



3）生产者事务

开启事务，必须开启幂等性。**Producer 在使用事务功能前，必须先 自定义一个唯一的 transactional.id。**有 了 transactional.id，即使客户端挂掉了， 它重启后也能继续处理未完成的事务

![image-20220428165259806](/assets/imgs/image-20220428165259806.png)

```java
// Kafka事务API
void initTransactions(); // 1 初始化事务
void beginTransaction() throws ProducerFencedException; // 2 开启事务
void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, String consumerGroupId) throwsProducerFencedException; // 3 在事务内提交已经消费的偏移量(主要用于消费者)
void commitTransaction() throws ProducerFencedException; // 4 提交事务
void abortTransaction() throws ProducerFencedException; // 5 放弃事务(类似于回滚事务的操作)
```

单个 Producer，使用事务保证消息的仅一次发送

```java
public class CustomProducerTransactions {
  public static void main(String[] args) throws InterruptedException {
    // 1. 创建 kafka 生产者的配置对象
    Properties properties = new Properties();
    // 2. 给 kafka 配置对象添加配置信息 
    properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092");
    // key,value 序列化
    properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    // 设置事务id(必须)，事务id任意起名
    properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "transaction_id_0");
    // 3. 创建 kafka 生产者对象
    KafkaProducer<String, String> kafkaProducer = new KafkaProducer<String, String>(properties);
    // 初始化事务 
    kafkaProducer.initTransactions(); 
    // 开启事务 
    kafkaProducer.beginTransaction(); 
    try {
      // 4. 调用 send 方法,发送消息 
      for (int i = 0; i < 5; i++) {
        // 发送消息
        kafkaProducer.send(new ProducerRecord<>("first", "silince " + i));
      }
      //提交事务
      kafkaProducer.commitTransaction();
    } catch (Exception e) { 
      // 终止事务
      kafkaProducer.abortTransaction(); } finally {
      // 5. 关闭资源
      kafkaProducer.close();
    }
  }
}
```



### 数据有序

单分区内，有序(还需有其他条件); 多分区，分区与分区间无序;

![image-20220428171145835](/assets/imgs/image-20220428171145835.png)

> 🤔单分区数据乱序问题？因为sender线程将数据发送到kafka集群的过程中存在重试机制。

1）kafka在1.x版本之前保证数据单分区有序，条件如下:

- **max.in.flight.requests.per.connection**=1(不需要考虑是否开启幂等性)。

2）kafka在**1.x及以后版本**保证数据单分区有序，条件如下: 

- 未开启幂等性：**max.in.flight.requests.per.connection(该参数指定了生产者在收到服务器响应之前可以发送多少个消息)**需要设置为**1**
- 开启幂等性：**max.in.flight.requests.per.connection**需要设置==小于等于5==。因为在kafka1.x以后，启用幂等后，**kafka服务端**会缓存producer发来的最近==5==个request的元数据， 故无论如何，都可以保证最近5个request的数据都是有序的(根据序列号)

![image-20220428171919457](/assets/imgs/image-20220428171919457.png)



#  Kafka Broker

## Zk 存储结构

![image-20220428181857947](/assets/imgs/image-20220428181857947.png)

## Broker工作流程

![image-20220428182003980](/assets/imgs/image-20220428182003980.png)

## Kafka 副本

1）副本基本信息

- Kafka 副本作用:提高数据可靠性。
- Kafka 默认副本 1 个，生产环境一般配置为 2 个，保证数据可靠性;太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。
- Kafka 中副本分为:**Leader 和 Follower**。Kafka 生产者只会把数据发往 Leader， 然后 Follower 会找 Leader 进行同步数据。
- Kafka 分区中的所有副本统称为 AR(Assigned Repllicas)。 
  - AR = ISR + OSR
  - **ISR**，表示和 Leader 保持同步的 Follower 集合。如果 Follower 长时间未向 Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。该时间阈值由 **replica.lag.time.max.ms** 参数设定，默认 30s。Leader 发生故障之后，就会从 ISR 中选举新的 Leader。
  - **OSR**，表示 Follower 与 Leader 副本同步时，延迟过多的副本。





2）**Leader** 选举流程

Kafka 集群中有一个 broker 的 Controller 会被选举为 Controller Leader，负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 Leader 选举等工作。Controller 的信息同步工作是依赖于 Zookeeper 的。

![image-20220428200354155](/assets/imgs/image-20220428200354155.png)



3）**Follower** 故障处理细节

- **LEO(Log End Offset)**:每个副本的最后一个offset，LEO其实就是最新的offset + 1。

- **HW(High Watermark)**:所有副本中最小的LEO 。

<img src="/assets/imgs/image-20220428221819121.png" alt="image-20220428201213159" style="zoom:50%;" />

此时follower2发生故障，Follower会读取本地磁盘记录的 上次的HW，并将1og文件高于HW的部分截取掉，从HW开始 向Leaderi进行同步。

![image-20220428201213159](/assets/imgs/image-20220428201213159.png)



4）**Leader** 故障处理细节

![image-20220428201236334](/assets/imgs/image-20220428201236334.png)

为保证多个副本之间的数据一致性，其余的Follower会先 将各自的log文件高于HW的部分截掉，然后从新的Leaderl同步数据。

<img src="/assets/imgs/image-20220428222212617.png" alt="image-20220428222212617" style="zoom:50%;" />

5）分区副本分配

> 如果 kafka 服务器只有 4 个节点，那么设置 kafka 的分区数大于服务器台数，在 kafka 底层如何分配存储副本呢?

创建 16 分区，3 个副本场景下会如下分配(示意图中省略了12-15分区)，目的是为了尽可能的保持==负载均衡==

![image-20220503232233272](/assets/imgs/image-20220503232233272.png)

![image-20220428223318373](/assets/imgs/image-20220428223318373.png)



## 生产经验

### 手动调整分区副本存储

> 需求🤔:创建一个新的topic，4个分区，两个副本，名称为three。将该topic的所有副本都存储到broker0和 broker1两台服务器上。

在生产环境中，每台服务器的配置和性能不一致，但是Kafka只会根据自己的代码规则创建对应的分区副本，就会导致个别服务器存储压力较大。所有需要手动调整分区副本的存储。

![image-20220503232436895](/assets/imgs/image-20220503232436895.png)

手动调整分区副本存储的步骤如下:

```shell
# 1.创建一个新的 topic，名称为 three。
bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --partitions 4 --replication-factor 2 -- topic three
# 2.查看分区副本存储情况。
bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic three
# 3.创建副本存储计划(所有副本都指定存储在 broker0、broker1 中)。
vim increase-replication-factor.json
{
   "version":1,
   "partitions":[{"topic":"three","partition":0,"replicas":[0,1]}, 
                 {"topic":"three","partition":1,"replicas":[0,1]}, 
                 {"topic":"three","partition":2,"replicas":[1,0]}, 
                 {"topic":"three","partition":3,"replicas":[1,0]}]
}
# 4.执行副本存储计划。
bin/kafka-reassign-partitions.sh -- bootstrap-server localhost:9092 --reassignment-json-file increase-replication-factor.json --execute
# 5.验证副本存储计划。
bin/kafka-reassign-partitions.sh -- bootstrap-server localhost:9092 --reassignment-json-file increase-replication-factor.json --verify
# 6.查看分区副本存储情况。
bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic three
```



### **Leader Partition** 负载平衡

正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些broker宕机，**会导致Leader Partition过于集中在其他少部分几台broker上**，这会导致少数几台broker的读写请求压力过高，其他宕机的 broker重启之后都是follower partition，读写请求很低，**造成集群负载不均衡**。

![image-20220503232919857](/assets/imgs/image-20220503232919857.png)

| 参数名称                                | 描述                                                         |
| --------------------------------------- | ------------------------------------------------------------ |
| auto.leader.rebalance.enable            | 默认是 true。 自动 Leader Partition 平衡。生产环 境中，==leader 重选举的代价比较大，可能会带来性能影响，建议设置为 false 关闭。== |
| leader.imbalance.per.broker.percentage  | 默认是 10%。每个 broker 允许的不平衡的 leader 的比率。如果每个 broker 超过了这个值，控制器会触发 leader 的平衡。 |
| leader.imbalance.check.interval.seconds | 默认值 300 秒。检查 leader 负载是否平衡的间隔 时间。         |



### 增加副本因子

在生产环境当中，由于某个主题的重要等级需要提升，我们考虑增加副本。副本数的增加需要先制定计划，然后根据计划执行。

```shell
# 1.创建 topic
bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --partitions 3 --replication-factor 1 -- topic four
# 2.手动增加副本存储。创建副本存储计划(所有副本都指定存储在 broker0、broker1、broker2 中)。
vim increase-replication-factor.json
{"version":1,"partitions":[{"topic":"four","partition":0,"replicas":[0,1,2]},{"topic":"four","partition":1,"replicas":[0,1,2]},{"t opic":"four","partition":2,"replicas":[0,1,2]}]}
# 3.执行副本存储计划。
bin/kafka-reassign-partitions.sh -- bootstrap-server localhost:9092 --reassignment-json-file increase-replication-factor.json --execute
```







## 文件存储

### 文件存储机制

Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是Producer生产的数据。

- Producer生产的数据会被不断==追加==到该log文件末端，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制， 将每个partition分为多个segment。
- 每个segment包括:“.index”文件、“.log”文件和.timeindex等文件。这些文件位于一个文件夹下，该文件夹的命名规则为:topic名称+分区序号，例如:first-0。

![image-20220504232359653](/assets/imgs/image-20220504232359653.png)



**index** 文件和 **log** 文件详解(稀疏索引)：

- 相对偏移量：如 `522(起始offset)+65(相对offerset) = 587(绝对offset)`

![image-20220504232716835](/assets/imgs/image-20220504232716835.png)

日志存储参数配置：

| 参数                     | 描述                                                         |
| ------------------------ | ------------------------------------------------------------ |
| log.segment.bytes        | Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分 成块的大小，默认值 1G。 |
| log.index.interval.bytes | 默认 4kb，kafka 里面每当写入了 4kb 大小的日志(.log)，然后就 往 index 文件里面记录一个索引。 稀疏索引。 |

### 文件清理策略

Kafka 中默认的日志保存时间为 7 天，可以通过调整如下参数修改保存时间。 

- log.retention.hours，最低优先级小时，默认7天。
- log.retention.minutes，分钟。
-  log.retention.ms，最高优先级毫秒。
- log.retention.check.interval.ms，负责设置检查周期，默认5分钟。 

> 🤔那么日志留存时间一旦超过了设置的时间，怎么处理呢?

Kafka 中提供的日志清理策略有 `delete` 和 `compact` 两种。

1）**delete 日志删除:将过期数据删除**

- log.cleanup.policy = delete 所有数据启用删除策略
  - 基于时间:默认打开。以 segment 中所有记录中的最大时间戳作为该文件时间戳。 
  - 基于大小:默认关闭。超过设置的所有日志总大小，删除最早的 segment。log.retention.bytes，默认等于-1，表示无穷大。

> 🤔如果一个 segment 中有一部分数据过期，一部分没有过期，怎么处理?

如采用基于时间的删除方式，因为segment 中所有记录中的最大时间戳作为该文件时间戳，因此会将整个segment删除。如果是基于大小的删除方式则不影响。

![image-20220505160824746](/assets/imgs/image-20220505160824746.png)



2）**compact日志压缩**：对于相同key的不同value值，只保留最后一个版本。

- log.cleanup.policy = compact 所有数据启用压缩策略

![image-20220505161201918](/assets/imgs/image-20220505161201918.png)

压缩后的offset可能是不连续的，比如上图中没有6，当从这些offset消费消息时，将会拿到比这个offset大 的offset对应的消息，实际上会拿到offset为7的消息，并从这个位置开始消费。

⚠️==这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。==



## 高效读写

> [Kafka 是如何实现高吞吐率的](http://www.silince.cn/2021/08/27/Kafka-%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%90%9E%E5%90%90%E7%8E%87%E7%9A%84/#%E9%A1%BA%E5%BA%8F%E8%AF%BB%E5%86%99)

**1**)**Kafka** 本身是分布式集群，可以采用分区技术，并行度高 

**2**)读数据采用稀疏索引，可以快速定位要消费的数据 

**3**)顺序写磁盘

Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端， 为顺序写。官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这 与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。

![image-20220505161340139](/assets/imgs/image-20220505161340139.png)

**4**)页缓存 **+** 零拷贝技术

- **零拷贝**:Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高。

- **PageCache页缓存**:Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入 PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。实际上PageCache是把尽可能多的空闲内存 都当做了磁盘缓存来使用。

  ![image-20220505161603741](/assets/imgs/image-20220505161603741.png)

相关参数：

- log.flush.interval.messages：强制页缓存刷写到磁盘的条数，默认是 long 的最大值， 9223372036854775807。一般不建议修改，交给系统自己管 理。
- log.flush.interval.ms：每隔多久，刷数据到磁盘，默认是 null。一般不建议修改， 交给系统自己管理。



# Kafka 消费者

## 消费方式



## 消费者工作流程



## 消费者API



## 生产经验





## offset位移



## 消费者事务



## 数据积压





